{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aravindchakravarti/ONNX_TensorRT/blob/main/MNIST_Classifier_ONNX_TRT_Inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0m2JWFliFfKT"
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "# Import core module\n",
        "import torch.nn as nn\n",
        "# We need support for functional programming\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "# For MNIST dataset\n",
        "from torchvision import datasets, transforms\n",
        "# For Global Average Pooling\n",
        "from torch.nn import AvgPool2d\n",
        "\n",
        "# For displaying images\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# You cannot live without Numpy in Python! :-D\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Define the model, load dataset and train!"
      ],
      "metadata": {
        "id": "ozXZzkcv6Zeq"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_Cx9q2QFgM7"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 8, 3, padding=1)      #I=28, O=28, RF=3\n",
        "        self.batch1 = nn.BatchNorm2d(num_features=8)\n",
        "        self.conv2 = nn.Conv2d(8, 8, 3, padding=1)      #I=28, O=28, RF=5\n",
        "        self.batch2 = nn.BatchNorm2d(num_features=8)\n",
        "        self.conv3 = nn.Conv2d(8, 12, 3, padding=1)     #I=28, O=28, RF=7\n",
        "        self.batch3 = nn.BatchNorm2d(num_features=12)\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)                 #I=28, O=14, RF=14\n",
        "        self.conv4 = nn.Conv2d(12, 10, 1)\n",
        "\n",
        "        self.conv5 = nn.Conv2d(10, 16, 3, padding=1)    #I=14, O=14, RF=17\n",
        "        self.batch4 = nn.BatchNorm2d(num_features=16)\n",
        "        self.conv6 = nn.Conv2d(16, 16, 3, padding=1)    #I=14, O=14, RF=20\n",
        "        self.batch5 = nn.BatchNorm2d(num_features=16)\n",
        "        self.conv7 = nn.Conv2d(16, 16, 3, padding=1)    #I=14, O=14, RF=23\n",
        "        self.batch6 = nn.BatchNorm2d(num_features=16)\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)                 #I=14, O=07, RF=26\n",
        "        self.conv8 = nn.Conv2d(16, 10, 1)\n",
        "\n",
        "        self.conv9 = nn.Conv2d(10, 32, 3, padding=0)    #I=07, O=05, RF=29\n",
        "        self.batch7 = nn.BatchNorm2d(num_features=32)\n",
        "        self.conv10 = nn.Conv2d(32, 10, 3, padding=0)   #I=05, O=03, RF=32\n",
        "        self.batch8 = nn.BatchNorm2d(num_features=10)\n",
        "        self.avg_pool = nn.AvgPool2d(kernel_size=3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.batch1(F.relu(self.conv1(x)))        #See above for Input\\\n",
        "        x = self.batch2(F.relu(self.conv2(x)))        #Output and Receptive Field\n",
        "        x = self.batch3(F.relu(self.conv3(x)))\n",
        "        x = self.pool1(x)\n",
        "        x = F.relu(self.conv4(x))\n",
        "\n",
        "        x = self.batch4(F.relu(self.conv5(x)))\n",
        "        x = self.batch5(F.relu(self.conv6(x)))\n",
        "        x = self.batch6(F.relu(self.conv7(x)))\n",
        "        x = self.pool2(x)\n",
        "        x = F.relu(self.conv8(x))\n",
        "\n",
        "        x = self.batch7(F.relu(self.conv9(x)))\n",
        "        x = self.batch8(F.relu(self.conv10(x)))\n",
        "        x = self.avg_pool(x)\n",
        "        x = x.view(-1, 10)                           # Don't want 10x1x1..\n",
        "        return F.log_softmax(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdydjYTZFyi3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18057268-3e4a-4e65-bc74-ffa97a8f07c2"
      },
      "source": [
        "!pip install torchsummary\n",
        "from torchsummary import summary\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print(device)\n",
        "model = Net().to(device)\n",
        "summary(model, input_size=(1, 28, 28))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.10/dist-packages (1.5.1)\n",
            "cuda\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1            [-1, 8, 28, 28]              80\n",
            "       BatchNorm2d-2            [-1, 8, 28, 28]              16\n",
            "            Conv2d-3            [-1, 8, 28, 28]             584\n",
            "       BatchNorm2d-4            [-1, 8, 28, 28]              16\n",
            "            Conv2d-5           [-1, 12, 28, 28]             876\n",
            "       BatchNorm2d-6           [-1, 12, 28, 28]              24\n",
            "         MaxPool2d-7           [-1, 12, 14, 14]               0\n",
            "            Conv2d-8           [-1, 10, 14, 14]             130\n",
            "            Conv2d-9           [-1, 16, 14, 14]           1,456\n",
            "      BatchNorm2d-10           [-1, 16, 14, 14]              32\n",
            "           Conv2d-11           [-1, 16, 14, 14]           2,320\n",
            "      BatchNorm2d-12           [-1, 16, 14, 14]              32\n",
            "           Conv2d-13           [-1, 16, 14, 14]           2,320\n",
            "      BatchNorm2d-14           [-1, 16, 14, 14]              32\n",
            "        MaxPool2d-15             [-1, 16, 7, 7]               0\n",
            "           Conv2d-16             [-1, 10, 7, 7]             170\n",
            "           Conv2d-17             [-1, 32, 5, 5]           2,912\n",
            "      BatchNorm2d-18             [-1, 32, 5, 5]              64\n",
            "           Conv2d-19             [-1, 10, 3, 3]           2,890\n",
            "      BatchNorm2d-20             [-1, 10, 3, 3]              20\n",
            "        AvgPool2d-21             [-1, 10, 1, 1]               0\n",
            "================================================================\n",
            "Total params: 13,974\n",
            "Trainable params: 13,974\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.53\n",
            "Params size (MB): 0.05\n",
            "Estimated Total Size (MB): 0.59\n",
            "----------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-6a328491a770>:45: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.log_softmax(x)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqTWLaM5GHgH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5e3e7e8-9e0e-4639-ec9b-a5bb51bfce00"
      },
      "source": [
        "torch.manual_seed(1)\n",
        "batch_size = 128\n",
        "\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=True, download=True,\n",
        "                    transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])),\n",
        "    batch_size=batch_size, shuffle=True, **kwargs)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])),\n",
        "    batch_size=batch_size, shuffle=True, **kwargs)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 120146083.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 98805623.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|██████████| 1648877/1648877 [00:00<00:00, 28592832.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 6219565.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fDefDhaFlwH"
      },
      "source": [
        "from tqdm import tqdm\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    # Disabling TQDM. Don't want to hurt CPU on my machine\n",
        "    #pbar = tqdm(train_loader)\n",
        "    #       If you enable TQDM, replace to pbar-- below\n",
        "    #                                           |\n",
        "    #                                           ▼\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        #pbar.set_description(desc= f'loss={loss.item()} batch_id={batch_idx}')\n",
        "\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMWbLWO6FuHb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75aa904d-3d6a-47f9-e2be-edf97faf1276"
      },
      "source": [
        "# Assign model to GPU and start training. I am training here only for 1 epoch as 90+ % accuracy is\n",
        "# sufficient for my experiment\n",
        "model = Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "for epoch in range(1, 2):\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "    test(model, device, test_loader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-6a328491a770>:45: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.log_softmax(x)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0814, Accuracy: 9820/10000 (98.20%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Inferencing using Model"
      ],
      "metadata": {
        "id": "v45UCcYj57_D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn the modelto inference only\n",
        "model.eval()\n",
        "\n",
        "# Read the image, scale it to 28x28 and convert it into Grayscale\n",
        "img = cv2.imread('/content/eight.jpg')\n",
        "img = cv2.resize(img, (28,28))\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "'''\n",
        "To match to MNIST dataset, we need to invert the image\n",
        "for more information check here -->\n",
        "https://stackoverflow.com/questions/58631088/why-are-my-neural-network-predictions-correct-when-applied-to-mnist-hand-drawn-i\n",
        "'''\n",
        "img= cv2.bitwise_not(img) # invert image\n",
        "plt.figure(figsize = (1,1))\n",
        "plt.imshow(img, cmap = plt.cm.binary)\n",
        "\n",
        "# Bring the image between 0->1 and perform zero mean, unit variance\n",
        "img = img.astype(np.float32)\n",
        "img = img/255\n",
        "img = (img-0.1307)/0.3081\n",
        "\n",
        "# We need image size as batch x channels x width x height\n",
        "img = np.expand_dims(img, 0)\n",
        "img = np.expand_dims(img, 0)\n",
        "img = torch.from_numpy(img).to(device)\n",
        "\n",
        "# Run the inference and get the max out from the neural network\n",
        "output = model(img)\n",
        "#print (output)\n",
        "pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "pred = pred.detach().cpu().numpy()\n",
        "\n",
        "print ('\\x1b[1;31m \\x1b[0;31m' + \"Charecter is ➡ {} \".format(pred.flatten()[0]) + '\\x1b[0m')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "id": "SdGwQ75-BCWh",
        "outputId": "56b84b1a-baf5-41f9-98ff-01aa697b3be9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;31m \u001b[0;31mCharecter is ➡ 8 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-6a328491a770>:45: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.log_softmax(x)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 100x100 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. Convert to ONNX and inference using ONNX"
      ],
      "metadata": {
        "id": "mnC5Q_pM6jZ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnx\n",
        "!pip install onnxruntime\n",
        "!pip install onnxscript\n",
        "\n",
        "import onnx\n",
        "import onnxruntime"
      ],
      "metadata": {
        "id": "3zulkMb0Bbjp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e5f094c-dde2-407a-ec07-b61ac19d9c5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnx\n",
            "  Downloading onnx-1.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from onnx) (1.23.5)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (3.20.3)\n",
            "Installing collected packages: onnx\n",
            "Successfully installed onnx-1.15.0\n",
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.16.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting coloredlogs (from onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (23.5.26)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (23.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.12)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Installing collected packages: humanfriendly, coloredlogs, onnxruntime\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.16.3\n",
            "Collecting onnxscript\n",
            "  Downloading onnxscript-0.1.0.dev20240111-py3-none-any.whl (551 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m551.2/551.2 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from onnxscript) (1.23.5)\n",
            "Requirement already satisfied: onnx>=1.14 in /usr/local/lib/python3.10/dist-packages (from onnxscript) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from onnxscript) (4.5.0)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx>=1.14->onnxscript) (3.20.3)\n",
            "Installing collected packages: onnxscript\n",
            "Successfully installed onnxscript-0.1.0.dev20240111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ONNX_FILE_PATH = 'MNIST_Classifier.onnx'\n",
        "\n",
        "# we need to give sample input the ONNX converter. Since, model work on 4 dimensions, 4th dimension being batch size,\n",
        "# we give batch size as 1.\n",
        "dummy_input = torch.randn(1, 1, 28, 28, device=\"cuda\") # 1080, 1920, device=\"cuda\")\n",
        "#dummy_input = dummy_input.half()\n",
        "\n",
        "with torch.no_grad():\n",
        "   model = model.to(device)\n",
        "   torch_out = model(dummy_input)\n",
        "\n",
        "# Export the model to ONNX\n",
        "torch.onnx.export(model,\n",
        "                  dummy_input,\n",
        "                  ONNX_FILE_PATH,\n",
        "                  opset_version = 12,\n",
        "                  input_names=['images'],\n",
        "                  output_names=['output0'],\n",
        "                  export_params=True)\n",
        "\n",
        "# If converted model has any error, then it will checker will give error!\n",
        "onnx_model = onnx.load('/content/MNIST_Classifier.onnx')\n",
        "onnx.checker.check_model(onnx_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isMUB9rD6-mK",
        "outputId": "f33f45fb-c170-4f7d-8134-af5ee07ef3d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-6a328491a770>:45: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.log_softmax(x)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let us create the ONNX run time with the ONNX file which we generated before\n",
        "ort_session = onnxruntime.InferenceSession(\"/content/MNIST_Classifier.onnx\")\n",
        "\n",
        "def to_numpy(tensor):\n",
        "    print (\"Type = {}\".format(type(tensor)))\n",
        "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
        "\n",
        "# compute ONNX Runtime output prediction\n",
        "ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(dummy_input)}\n",
        "ort_outs = ort_session.run(None, ort_inputs)\n",
        "\n",
        "print (\"torch_out size = {}\".format(torch_out.shape))\n",
        "print (\"ort_outs[0] size = {}\".format((ort_outs[0]).shape))\n",
        "\n",
        "# compare ONNX Runtime and PyTorch results\n",
        "np.testing.assert_allclose(to_numpy(torch_out), ort_outs[0], rtol=1e-03, atol=1e-05)\n",
        "\n",
        "print(\"Exported model has been tested with ONNXRuntime, and the result looks good!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4ADBHIj8Gdd",
        "outputId": "82cc9476-f8f8-437d-805a-60944cf250a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type = <class 'torch.Tensor'>\n",
            "torch_out size = torch.Size([1, 10])\n",
            "ort_outs[0] size = (1, 10)\n",
            "Type = <class 'torch.Tensor'>\n",
            "Exported model has been tested with ONNXRuntime, and the result looks good!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the image, scale it to 28x28 and convert it into Grayscale\n",
        "img = cv2.imread('/content/seven.jpg')\n",
        "img = cv2.resize(img, (28,28))\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "'''\n",
        "To match to MNIST dataset, we need to invert the image\n",
        "for more information check here -->\n",
        "https://stackoverflow.com/questions/58631088/why-are-my-neural-network-predictions-correct-when-applied-to-mnist-hand-drawn-i\n",
        "'''\n",
        "img= cv2.bitwise_not(img) # invert image\n",
        "plt.figure(figsize = (1,1))\n",
        "plt.imshow(img, cmap = plt.cm.binary)\n",
        "\n",
        "# Bring the image between 0->1 and perform zero mean, unit variance\n",
        "img = img.astype(np.float32)\n",
        "img = img/255\n",
        "img = (img-0.1307)/0.3081\n",
        "\n",
        "# We need image size as batch x channels x width x height\n",
        "img = np.expand_dims(img, 0)\n",
        "img = np.expand_dims(img, 0)\n",
        "img = torch.from_numpy(img).to(device)\n",
        "\n",
        "ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(img)}\n",
        "ort_outs = ort_session.run(None, ort_inputs)\n",
        "\n",
        "ort_outs_tensor = torch.from_numpy(ort_outs[0])\n",
        "#print(ort_outs_tensor.shape)\n",
        "\n",
        "pred = ort_outs_tensor.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "pred = pred.detach().cpu().numpy()\n",
        "\n",
        "print ('\\x1b[1;31m \\x1b[0;31m'+\"Charecter is ➡ {} \".format(pred.flatten()[0])+'\\x1b[0m')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "V_iK_4-18-y9",
        "outputId": "6600ab5e-4059-42ed-a482-f602b0fe9b76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type = <class 'torch.Tensor'>\n",
            "\u001b[1;31m \u001b[0;31mCharecter is ➡ 7 \u001b[0m\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 100x100 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Converting the model to tensorRT and inferencing it"
      ],
      "metadata": {
        "id": "_Ol0aK569-h4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade setuptools pip --user\n",
        "!pip install --ignore-installed PyYAML\n",
        "!pip install Pillow\n",
        "\n",
        "!pip install nvidia-pyindex\n",
        "!pip install --upgrade nvidia-tensorrt\n",
        "!pip install pycuda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yq9L_YR8--v9",
        "outputId": "82b6e38a-ca61-4751-81a2-5a8739166fba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (67.7.2)\n",
            "Collecting setuptools\n",
            "  Downloading setuptools-69.0.3-py3-none-any.whl (819 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m819.5/819.5 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-23.3.2-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: setuptools, pip\n",
            "\u001b[33m  WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pip-23.3.2 setuptools-69.0.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack",
                  "pkg_resources",
                  "setuptools"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyYAML\n",
            "  Downloading PyYAML-6.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Downloading PyYAML-6.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (705 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m705.5/705.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyYAML\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed PyYAML-6.0.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "yaml"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (9.4.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting nvidia-pyindex\n",
            "  Downloading nvidia-pyindex-1.0.9.tar.gz (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: nvidia-pyindex\n",
            "  Building wheel for nvidia-pyindex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nvidia-pyindex: filename=nvidia_pyindex-1.0.9-py3-none-any.whl size=8418 sha256=368997bdbe7c09ce72f3a5ecac435d50264dd5cb2e41598cf05b2d6e9536e4c2\n",
            "  Stored in directory: /root/.cache/pip/wheels/2c/af/d0/7a12f82cab69f65d51107f48bcd6179e29b9a69a90546332b3\n",
            "Successfully built nvidia-pyindex\n",
            "Installing collected packages: nvidia-pyindex\n",
            "Successfully installed nvidia-pyindex-1.0.9\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting nvidia-tensorrt\n",
            "  Downloading nvidia_tensorrt-99.0.0-py3-none-manylinux_2_17_x86_64.whl (17 kB)\n",
            "Collecting tensorrt (from nvidia-tensorrt)\n",
            "  Downloading tensorrt-8.6.1.post1.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: tensorrt\n",
            "  Building wheel for tensorrt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorrt: filename=tensorrt-8.6.1.post1-py2.py3-none-any.whl size=17283 sha256=7fcb5a6fa9e6a42b84e86fbf32fd441366d55ba112cd63aae614569233e712bc\n",
            "  Stored in directory: /root/.cache/pip/wheels/f4/c8/0e/b79b08e45752491b9acfdbd69e8a609e8b2ed7640dda5a3e59\n",
            "Successfully built tensorrt\n",
            "Installing collected packages: tensorrt, nvidia-tensorrt\n",
            "Successfully installed nvidia-tensorrt-99.0.0 tensorrt-8.6.1.post1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting pycuda\n",
            "  Downloading pycuda-2024.1.tar.gz (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pytools>=2011.2 (from pycuda)\n",
            "  Downloading pytools-2023.1.1-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: appdirs>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from pycuda) (1.4.4)\n",
            "Collecting mako (from pycuda)\n",
            "  Downloading Mako-1.3.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from pytools>=2011.2->pycuda) (4.1.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pytools>=2011.2->pycuda) (4.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from mako->pycuda) (2.1.3)\n",
            "Downloading pytools-2023.1.1-py2.py3-none-any.whl (70 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.6/70.6 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Mako-1.3.0-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pycuda\n",
            "  Building wheel for pycuda (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycuda: filename=pycuda-2024.1-cp310-cp310-linux_x86_64.whl size=661205 sha256=8a0ba9ad2b5317b4810e767efacf73cd7b5c74b25ebde54a9d24086f044fdad9\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/34/d2/9a349255a4eca3a486d82c79d21e138ce2ccd90f414d9d72b8\n",
            "Successfully built pycuda\n",
            "Installing collected packages: pytools, mako, pycuda\n",
            "Successfully installed mako-1.3.0 pycuda-2024.1 pytools-2023.1.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import OrderedDict,namedtuple\n",
        "import tensorrt as trt\n",
        "import time"
      ],
      "metadata": {
        "id": "fMqeJ638BGKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download ONNX to TensorRT converter\n",
        "%cd /content/\n",
        "!git clone https://github.com/Linaom1214/tensorrt-python.git\n",
        "\n",
        "%cd tensorrt-python\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAX92BP0-K8Q",
        "outputId": "f9a14efa-9293-4fbe-c585-92fb698ec837"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'tensorrt-python'...\n",
            "remote: Enumerating objects: 337, done.\u001b[K\n",
            "remote: Counting objects: 100% (83/83), done.\u001b[K\n",
            "remote: Compressing objects: 100% (26/26), done.\u001b[K\n",
            "remote: Total 337 (delta 61), reused 57 (delta 57), pack-reused 254\u001b[K\n",
            "Receiving objects: 100% (337/337), 132.56 MiB | 38.35 MiB/s, done.\n",
            "Resolving deltas: 100% (169/169), done.\n",
            "/content/tensorrt-python\n",
            "cpp  export.py\timage_batch.py\tREADME_CN.md  README.md  src  trt.py  utils\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Export TensorRT-engine model\n",
        "!python export.py -o /content/MNIST_Classifier.onnx -e ./MNIST_Classifier_engine.trt -p fp32"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_oD4Ulwv-ybZ",
        "outputId": "fd274dc8-223a-4a7d-b813-31c199f8c10a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(onnx='/content/MNIST_Classifier.onnx', engine='./MNIST_Classifier_engine.trt', precision='fp32', verbose=False, workspace=1, calib_input=None, calib_cache='./calibration.cache', calib_num_images=5000, calib_batch_size=8, end2end=False, conf_thres=0.4, iou_thres=0.5, max_det=100, v8=False)\n",
            "[01/11/2024-06:11:39] [TRT] [I] [MemUsageChange] Init CUDA: CPU +1, GPU +0, now: CPU 27, GPU 545 (MiB)\n",
            "[01/11/2024-06:11:53] [TRT] [I] [MemUsageChange] Init builder kernel library: CPU +888, GPU +174, now: CPU 992, GPU 719 (MiB)\n",
            "[01/11/2024-06:11:53] [TRT] [W] onnx2trt_utils.cpp:374: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.\n",
            "Network Description\n",
            "Input 'images' with shape (1, 1, 28, 28) and dtype DataType.FLOAT\n",
            "Output 'output0' with shape (1, 10) and dtype DataType.FLOAT\n",
            "Building fp32 Engine in /content/tensorrt-python/MNIST_Classifier_engine.trt\n",
            "[01/11/2024-06:11:53] [TRT] [I] BuilderFlag::kTF32 is set but hardware does not support TF32. Disabling TF32.\n",
            "[01/11/2024-06:11:53] [TRT] [I] Graph optimization time: 0.00203376 seconds.\n",
            "[01/11/2024-06:11:53] [TRT] [I] BuilderFlag::kTF32 is set but hardware does not support TF32. Disabling TF32.\n",
            "[01/11/2024-06:11:53] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
            "[01/11/2024-06:11:59] [TRT] [I] Detected 1 inputs and 1 output network tensors.\n",
            "[01/11/2024-06:11:59] [TRT] [I] Total Host Persistent Memory: 59968\n",
            "[01/11/2024-06:11:59] [TRT] [I] Total Device Persistent Memory: 0\n",
            "[01/11/2024-06:11:59] [TRT] [I] Total Scratch Memory: 0\n",
            "[01/11/2024-06:11:59] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 0 MiB, GPU 4 MiB\n",
            "[01/11/2024-06:11:59] [TRT] [I] [BlockAssignment] Started assigning block shifts. This will take 22 steps to complete.\n",
            "[01/11/2024-06:11:59] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 0.171204ms to assign 2 blocks to 22 nodes requiring 75776 bytes.\n",
            "[01/11/2024-06:11:59] [TRT] [I] Total Activation Memory: 75776\n",
            "[01/11/2024-06:11:59] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +0, GPU +4, now: CPU 0, GPU 4 (MiB)\n",
            "Serializing engine to file: /content/tensorrt-python/MNIST_Classifier_engine.trt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w = '/content/tensorrt-python/MNIST_Classifier_engine.trt'\n",
        "\n",
        "# Infer TensorRT Engine\n",
        "Binding = namedtuple('Binding', ('name', 'dtype', 'shape', 'data', 'ptr'))\n",
        "logger = trt.Logger(trt.Logger.INFO)\n",
        "trt.init_libnvinfer_plugins(logger, namespace=\"\")\n",
        "with open(w, 'rb') as f, trt.Runtime(logger) as runtime:\n",
        "    model = runtime.deserialize_cuda_engine(f.read())\n",
        "bindings = OrderedDict()\n",
        "for index in range(model.num_bindings):\n",
        "    name = model.get_binding_name(index)\n",
        "    dtype = trt.nptype(model.get_binding_dtype(index))\n",
        "    shape = tuple(model.get_binding_shape(index))\n",
        "    data = torch.from_numpy(np.empty(shape, dtype=np.dtype(dtype))).to(device)\n",
        "    bindings[name] = Binding(name, dtype, shape, data, int(data.data_ptr()))\n",
        "\n",
        "    print (\"name = {}\".format(name))\n",
        "    print (\"dtype = {}\".format(dtype))\n",
        "    print (\"shape = {}\".format(shape))\n",
        "binding_addrs = OrderedDict((n, d.ptr) for n, d in bindings.items())\n",
        "context = model.create_execution_context()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7iXVQFhAAy9e",
        "outputId": "78ab81ee-4b5a-495f-a8f3-bb884631a8f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "name = images\n",
            "dtype = <class 'numpy.float32'>\n",
            "shape = (1, 1, 28, 28)\n",
            "name = output0\n",
            "dtype = <class 'numpy.float32'>\n",
            "shape = (1, 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-120be86e3eea>:11: DeprecationWarning: Use get_tensor_name instead.\n",
            "  name = model.get_binding_name(index)\n",
            "<ipython-input-16-120be86e3eea>:12: DeprecationWarning: Use get_tensor_dtype instead.\n",
            "  dtype = trt.nptype(model.get_binding_dtype(index))\n",
            "<ipython-input-16-120be86e3eea>:13: DeprecationWarning: Use get_tensor_shape instead.\n",
            "  shape = tuple(model.get_binding_shape(index))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img = cv2.imread('/content/seven.jpg')\n",
        "img = cv2.resize(img, (28,28))\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "img= cv2.bitwise_not(img) # invert image\n",
        "plt.imshow(img, cmap = plt.cm.binary)\n",
        "\n",
        "img = img.astype(np.float32)\n",
        "img = img/255\n",
        "img = (img-0.1307)/0.3081\n",
        "\n",
        "img = np.expand_dims(img, 0)\n",
        "img = np.expand_dims(img, 0)\n",
        "img = torch.from_numpy(img).to(device)\n",
        "\n",
        "# warmup for 10 times\n",
        "for _ in range(10):\n",
        "    tmp = torch.randn(1,3,640,640).to(device)\n",
        "    binding_addrs['images'] = int(tmp.data_ptr())\n",
        "    context.execute_v2(list(binding_addrs.values()))\n",
        "\n",
        "start = time.perf_counter()\n",
        "binding_addrs['images'] = int(img.data_ptr())\n",
        "context.execute_v2(list(binding_addrs.values()))\n",
        "print(f'Cost {time.perf_counter()-start} s')\n",
        "\n",
        "outputs = bindings['output0'].data\n",
        "\n",
        "print (\"Output shape = {}\".format(outputs.shape))\n",
        "\n",
        "pred = outputs.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "pred = pred.detach().cpu().numpy()\n",
        "\n",
        "print (\"Charecter is ➡ {} \".format(pred.flatten()[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "id": "tzMFdohkBR-7",
        "outputId": "0bb895b2-7a72-4139-f2cb-050af8a81cc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cost 0.0005135650000056557 s\n",
            "Output shape = torch.Size([1, 10])\n",
            "Charecter is ➡ 7 \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}